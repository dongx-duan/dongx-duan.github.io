<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" 
    href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" 
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" 
    crossorigin="anonymous">

  <link rel="stylesheet" 
    href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css"
    integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" 
    crossorigin="anonymous">

  <style>
    body {
      font-size: 16px;
      color: #333;
    }
    a {
      cursor: pointer;
    }
    a:link {
      color: #4896DF;
    }
    .sidebar {
      
    }
    .sidebar div {
      margin-top: 6px;
    }
    .sidebar .section{
      margin-top: 12px;
    }
    .main{
    }
    .main em{
      font-weight: bold;
    }
    .main li{
      margin-top: 4px;
    }
    .main p{
      margin-top: 4px;
    }
  </style>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
  </script>
</head>

<body>
  <div class="container">
    <div class="row">
      <div class="col-md-9 col-md-offset-3">
        <div class="page-header">
        <h1 >Learning Deep Structures <br/>
          <small style="color:#666">a note on deep learning and probabilistic graphic models</small>
        </h1>
      </div>
      </div>
    </div>
    

    <div class="row">
      <div class="col-md-3 sidebar">
        <div><a style="font-size: 1.5em;"> Dongxu Duan </a> </div>
        <div> Machine Learning, Deep Learning, Visualization </div>
        <br>
        <div> <a href="#intro"> Why we are here? </a> </div>
        <div class="section"> Part 1 </div>
        <div> <a href="#slp"> Sequence Labeling Problem </a></div>
        <div> <a href="#rnn"> Recurrent Neural Network </a></div>
        <div> <a href="#crf"> Conditional Random Field </a></div>
        <div> <a href="#ner"> Application: Name Entity Recognition </a> </div>
        <div class="section"> Part 2 </div>
        <div> <a href="#vae"> Variational Auto-Encoder </a></div>
        <div> <a href="#vrnn"> Variational RNN </a></div>
        <br>
        <div> <a href="#ref"> Reference</a></div>
        <div> <a href="#apnd"> Appendix </a></div>
      </div>


      <div class="col-md-9 main">
        <div class="row">
          <div> <a id="#intro"></a><em>Why we are here?</em></div>
          <div>
            <p>
              The rapid progress in Machine Learning and Artificial Intelligence in recent years is largely due to the renaissance of the artificial neural network, specifically, the deep convolution neural network(CNN) and deep recurrent neural network(RNN). In generally, it's called Deep Learning. The effectiveness of Deep Learning have been proved in many applications, such as image recognition, image segmentation, machine translation, conversation generation, and playing PC games etc. In some of them, machine has already beaten human. However, the reason of such powerful capability Deep Learning is still unclear. There are two mainstream views: the first, each layer of the neural network is a non-linear function, and stack of numbers of such layers could approximates any complex function. The second, Deep Learning is good at constructing distributed, sparse and abstract features which are critical in machine learning tasks. Despite of such perplexities, CNNs and RNNs are easy to train by back propagation method(BP), which aids their popularity.
            </p>
            <p>
              Probabilistic graphic models (a huge famaly including Hidden Molkev Model, Condition Random Field, Restricted Bolzmann Machine etc) are also hot topics in machine learning. Koller and Friedman wrote a 1200 pages book on this topic. Comparing to Deep Learning, probabilistic graphic models are better in defining structures and relationships but dificult in training and inference. Infusing probabilistic graphic models into Deep Learning opens a new way.
            </p>
            <p>
              In the first part of this tutorial, we will examinate the details of recurrent neural networks and conditional random field, and apply them in solving the sequence labeling problem. In the second part, we will go through some advanced topics of combining graphic model and Deep Learning. 
            </p>
          </div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#slp"> </a><em> Sequence Labeling Problem </em></div>
          <div>

          </div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#rnn"> </a><em> Recurrent Neural Network </em></div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#crf"> </a><em> Conditional Random Field </em></div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#ner"> </a><em> Application: Name Entity Recognition </em></div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#vae"> </a><em> Variational Auto-Encoder </em></div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#vrnn"> </a><em> Variational Recurrent Neural Network </em></div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#ref"> </a><em> Reference </em></div>
          <div>
            <ul>

              <li>Representation Learning, by Bengio, etc
                <a href="http://www.cl.uni-heidelberg.de/courses/ws14/deepl/BengioETAL12.pdf">
                </a>Representation Learning: A Review and New Perspectives</li>
              </li>

              <li>A great tutorial on LSTM, by r2rt 
                <a href="http://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html">
                Written Memories: Understanding, Deriving and Extending the LSTM </a> </li>

              <li>Another tutorial on LSTM with great charts, by colah
                <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">
                Understanding LSTM Networks</a> </li>

              <li>Several amazing applications of RNN, by Karpathy 
                <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">
                The Unreasonable Effectiveness of Recurrent Neural Networks</a> </li>

              <li>Clear math of CRF, by Michael Collins 
                <a href="http://www.cs.columbia.edu/~mcollins/crf.pdf">
                Log-Linear Models, MEMMs, and CRFs</a></li>

            </ul>
          </div>
        </div>
        <hr>


        <div class="row">
          <div> <a id="#apnd"> </a><em> Appendix </em></div>
          <div>
            <ul>

              <li>Implementation of Bi-LSTM + CRF model, by me. 
                  I hope it would help to understand what i have written.
                  <a href="https://github.com/dongx-duan/crf"> Code</a></li>
            
            </ul>
          </div>
        </div>
        <hr>

      </div>
    </div>
  </div>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"
    integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" 
    crossorigin="anonymous"></script>
  
</body>
</html>
